{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE GOAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# import data types to cast data and define schema\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, \\\n",
    "                                DecimalType, FloatType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode/sql/metadata/hive\")\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n",
    "# .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode/sql/metadata/hive\") \\\n",
    "\n",
    "hive_folder = \"/Users/vk/Documents/Python/holmes_moriarty_sql/src/hive_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf metastore_db/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select database to use and create tables in\n",
    "\n",
    "spark.sql(\"use default\").show(10, False)  # 'default' is a pre-created database where we can create tables\n",
    "# (we could have skipped this statement but it makes it more explicity which database we use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|default  |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# we could also create our tables in our own custom database using:\n",
    "# spark.sql(\"create database moriarty_db\")\n",
    "# spark.sql(\"use moriarty_db\")\n",
    "spark.sql(\"show tables\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables = [i[\"tableName\"] for i in spark.sql(\"show tables\").collect()]\n",
    "# tables\n",
    "# for table in tables:\n",
    "#     spark.sql(\"drop table if exists {}\".format(table))\n",
    "    \n",
    "# spark.sql(\"show tables\").show(10, False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime_type_profit_France.txt          criminals_Germany.csv\r\n",
      "crime_type_profit_Germany.txt         criminals_Netherlands.csv\r\n",
      "crime_type_profit_Netherlands.txt     criminals_United Kingdom.csv\r\n",
      "crime_type_profit_United Kingdom.txt  id_dates.csv\r\n",
      "criminals_France.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criminals_country_template=\"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS criminals_{} (\n",
    " id int,\n",
    " name string,\n",
    " alias string,\n",
    " latitude float,\n",
    " longitude float,\n",
    " country string\n",
    "    )\n",
    "STORED AS ORC\n",
    "LOCATION '{}'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_schema(df, schema):\n",
    "    \"\"\"\"\"\"\n",
    "    # apply schema\n",
    "    df = spark.createDataFrame(df.rdd, schema=schema)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: United Kingdom, rows: 306\n",
      "Country: Germany, rows: 264\n",
      "Country: Netherlands, rows: 250\n",
      "Country: France, rows: 349\n",
      "+--------+------------------------+-----------+\n",
      "|database|tableName               |isTemporary|\n",
      "+--------+------------------------+-----------+\n",
      "|default |criminals_france        |false      |\n",
      "|default |criminals_germany       |false      |\n",
      "|default |criminals_netherlands   |false      |\n",
      "|default |criminals_united_kingdom|false      |\n",
      "+--------+------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "\n",
    "def rename_cols(df, new_col_names):\n",
    "    \"\"\"\"\"\"\n",
    "    for col, new_col in zip(df.columns, new_col_names):\n",
    "        df = df.withColumnRenamed(col, new_col)\n",
    "        \n",
    "    return df\n",
    "\n",
    "#explore the dataframes: column names, shapes and combine into a single dataframe\n",
    "country_list = [\"United Kingdom\", \"Germany\", \"Netherlands\", \"France\"]\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"alias\", StringType(), True),\n",
    "    StructField(\"latitude\", FloatType(), True),\n",
    "    StructField(\"longitude\", FloatType(), True),\n",
    "    StructField(\"country\", StringType(), True)\n",
    "])\n",
    "\n",
    "for country_ in country_list:\n",
    "    file_name = \"./data/criminals_{}.csv\".format(country_)\n",
    "    df = spark.read.csv(file_name, header=True, inferSchema=True)\n",
    "    print(\"Country: {}, rows: {}\".format(country_, df.count()))\n",
    "    new_col_names = [\"id\", \"name\", \"alias\", \"latitude\", \"longitude\"]\n",
    "    df = rename_cols(df, new_col_names)\n",
    "    df = df.withColumn('country', F.lit(country_))\n",
    "    country_ = \"_\".join(country_.split()).lower()  # 'United Kingdom' as space in it and thus is an illigal table name\n",
    "    df = apply_schema(df, schema)\n",
    "    location = os.path.join(hive_folder, 'criminals_{}'.format(country_))\n",
    "    df.persist()\n",
    "    df.write.orc(location, mode=\"overwrite\")\n",
    "    df.unpersist()\n",
    "\n",
    "    \n",
    "    # register table\n",
    "    spark.sql(criminals_country_template.format(country_, location))\n",
    "    \n",
    "spark.sql(\"show tables\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+-----+--------+---------+--------------+\n",
      "|id |name                    |alias|latitude|longitude|country       |\n",
      "+---+------------------------+-----+--------+---------+--------------+\n",
      "|0  |Ms. Diane Barnett       |null |51.3327 |-0.0328  |United Kingdom|\n",
      "|1  |Elizabeth McDonald      |null |51.3732 |-0.0396  |United Kingdom|\n",
      "|2  |Jacqueline Martin-Winter|null |51.3536 |-0.223   |United Kingdom|\n",
      "+---+------------------------+-----+--------+---------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from criminals_united_kingdom\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criminals_unioned count: 1169\n",
      "+---+--------------------+-----+--------+---------+-------+\n",
      "| id|                name|alias|latitude|longitude|country|\n",
      "+---+--------------------+-----+--------+---------+-------+\n",
      "|  0|Henriette Thomas ...| null| 48.9072|   2.2521| France|\n",
      "|190|Inès Martins de l...| null| 49.0029|    2.251| France|\n",
      "|215|         Isaac Labbe| null| 48.8873|   2.3601| France|\n",
      "+---+--------------------+-----+--------+---------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_criminals_combined = spark.sql(\"\"\"select * from criminals_france\n",
    "          union\n",
    "          select * from criminals_germany\n",
    "          union\n",
    "          select * from criminals_netherlands\n",
    "          union\n",
    "          select * from criminals_united_kingdom\"\"\")\n",
    "\n",
    "print(\"criminals_unioned count: {}\".format(df_criminals_combined.count()))\n",
    "\n",
    "df_criminals_combined.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|country       |count(1)|\n",
      "+--------------+--------+\n",
      "|Germany       |264     |\n",
      "|France        |349     |\n",
      "|United Kingdom|306     |\n",
      "|Netherlands   |250     |\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_criminals_combined.groupBy(\"country\").agg(F.count(\"*\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register temp table\n",
    "df_criminals_combined.registerTempTable(\"criminals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|country       |\n",
      "+--------------+\n",
      "|Germany       |\n",
      "|France        |\n",
      "|United Kingdom|\n",
      "|Netherlands   |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criminals_df = spark.sql(\"select distinct country from criminals\")\n",
    "# print(\"Table (read-in) count: {}\".format(criminals_df.count()))\n",
    "criminals_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+--------------------+\n",
      "|country       |avg_lat           |avg_lon             |\n",
      "+--------------+------------------+--------------------+\n",
      "|France        |48.86060943166301 |2.364566761989648   |\n",
      "|Germany       |50.097135254831024|8.678964380061988   |\n",
      "|Netherlands   |52.37530560302734 |4.900951610565185   |\n",
      "|United Kingdom|51.50456336276983 |-0.12400588218790493|\n",
      "+--------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate mean latitude and longitude to identify the major financial centers (cities)\n",
    "# (copy and paste the lat, lon values into Google Maps)\n",
    "# dataframe.filter(df['salary'] > 100000).agg({\"age\": \"avg\"})\n",
    "\n",
    "spark.sql(\"\"\"select country, \n",
    "                    AVG(latitude) as avg_lat, \n",
    "                    AVG(longitude) as avg_lon\n",
    "                    from criminals\n",
    "                    group by country\n",
    "                    order by country\"\"\").show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+-------+\n",
      "|country       |avg_lat|avg_lon|\n",
      "+--------------+-------+-------+\n",
      "|France        |48.8606|2.3646 |\n",
      "|Germany       |50.0971|8.679  |\n",
      "|Netherlands   |52.3753|4.901  |\n",
      "|United Kingdom|51.5046|-0.124 |\n",
      "+--------------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select country,\n",
    "                    ROUND(AVG(latitude), 4) as avg_lat,\n",
    "                    ROUND(AVG(longitude), 4) as avg_lon\n",
    "                from criminals\n",
    "                 group by country\n",
    "                 order by country\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'United Kingdom': 'London',\n",
       " 'Germany': 'Frankfurt',\n",
       " 'Netherlands': 'Amsterdam',\n",
       " 'France': 'Paris'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the city name to the df\n",
    "\n",
    "#it can be done using a series of if/else statements, such as 'if country_ == 'France': city = 'Paris', etc. OR\n",
    "# using a dictionary as below:\n",
    "country_city_dict = {\"United Kingdom\": \"London\", \"Germany\": \"Frankfurt\", \"Netherlands\": \"Amsterdam\", \"France\": \"Paris\"}\n",
    "country_city_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+-----+--------+---------+-----------+---------+\n",
      "|id |name                     |alias|latitude|longitude|country    |city     |\n",
      "+---+-------------------------+-----+--------+---------+-----------+---------+\n",
      "|0  |Henriette Thomas du Peron|null |48.9072 |2.2521   |France     |Paris    |\n",
      "|190|Inès Martins de la Morel |null |49.0029 |2.251    |France     |Paris    |\n",
      "|215|Isaac Labbe              |null |48.8873 |2.3601   |France     |Paris    |\n",
      "|244|Aimée-Margot Martins     |null |48.885  |2.5288   |France     |Paris    |\n",
      "|297|Olivier Lopez            |Flako|48.616  |2.1133   |France     |Paris    |\n",
      "|326|Philippine Traore        |null |49.0171 |2.4338   |France     |Paris    |\n",
      "|23 |Dipl.-Ing. Dennis Hesse  |null |50.0266 |8.6771   |Germany    |Frankfurt|\n",
      "|202|Ali Dowerg               |null |50.1855 |8.5548   |Germany    |Frankfurt|\n",
      "|243|Tomas Mies               |null |50.0033 |8.9106   |Germany    |Frankfurt|\n",
      "|232|Liam Janssen-Frankhuizen |null |52.5289 |4.8684   |Netherlands|Amsterdam|\n",
      "+---+-------------------------+-----+--------+---------+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select *, \n",
    "                case \n",
    "                    when country = 'United Kingdom' then 'London'\n",
    "                    when country = 'France' then 'Paris'\n",
    "                    when country = 'Germany' then 'Frankfurt'\n",
    "                    when country = 'Netherlands' then 'Amsterdam'\n",
    "                end as city\n",
    "            from criminals\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+-----+-----------+---------+\n",
      "|id |name                     |alias|country    |city     |\n",
      "+---+-------------------------+-----+-----------+---------+\n",
      "|0  |Henriette Thomas du Peron|     |France     |Paris    |\n",
      "|190|Inès Martins de la Morel |     |France     |Paris    |\n",
      "|215|Isaac Labbe              |     |France     |Paris    |\n",
      "|244|Aimée-Margot Martins     |     |France     |Paris    |\n",
      "|297|Olivier Lopez            |Flako|France     |Paris    |\n",
      "|326|Philippine Traore        |     |France     |Paris    |\n",
      "|23 |Dipl.-Ing. Dennis Hesse  |     |Germany    |Frankfurt|\n",
      "|202|Ali Dowerg               |     |Germany    |Frankfurt|\n",
      "|243|Tomas Mies               |     |Germany    |Frankfurt|\n",
      "|232|Liam Janssen-Frankhuizen |     |Netherlands|Amsterdam|\n",
      "+---+-------------------------+-----+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill Nas with empty string \n",
    "# we'll also assign this new data to a variable name for saving and creating a new table to use later\n",
    "# (note that 'show' method is moved to the spark dataframe)\n",
    "criminals_with_city_df = spark.sql(\"\"\"select id, name,\n",
    "                case\n",
    "                    when alias is null then ''\n",
    "                    else alias\n",
    "                end as alias,\n",
    "                country,\n",
    "                case \n",
    "                    when country = 'United Kingdom' then 'London'\n",
    "                    when country = 'France' then 'Paris'\n",
    "                    when country = 'Germany' then 'Frankfurt'\n",
    "                    when country = 'Netherlands' then 'Amsterdam'\n",
    "                end as city\n",
    "            from criminals\"\"\")\n",
    "\n",
    "criminals_with_city_df.cache()\n",
    "criminals_with_city_df.registerTempTable(\"criminals_with_city\")\n",
    "\n",
    "criminals_with_city_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Germany'),\n",
       " Row(country='France'),\n",
       " Row(country='United Kingdom'),\n",
       " Row(country='Netherlands')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select distinct country from criminals\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Germany'),\n",
       " Row(country='France'),\n",
       " Row(country='United Kingdom'),\n",
       " Row(country='Netherlands')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the data is readable\n",
    "spark.sql(\"select distinct country from criminals_with_city\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|country       |count(1)|\n",
      "+--------------+--------+\n",
      "|Germany       |264     |\n",
      "|France        |349     |\n",
      "|United Kingdom|306     |\n",
      "|Netherlands   |250     |\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criminals_with_city_df.groupBy(\"country\").agg(F.count(\"*\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+-----------+\n",
      "|database|tableName               |isTemporary|\n",
      "+--------+------------------------+-----------+\n",
      "|default |criminals_france        |false      |\n",
      "|default |criminals_germany       |false      |\n",
      "|default |criminals_netherlands   |false      |\n",
      "|default |criminals_united_kingdom|false      |\n",
      "|        |criminals               |true       |\n",
      "|        |criminals_with_city     |true       |\n",
      "+--------+------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "Add crime_type and profit info to criminals. \n",
    "#(merge/join) criminals table with the crime type and profit information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Germany'),\n",
       " Row(country='France'),\n",
       " Row(country='United Kingdom'),\n",
       " Row(country='Netherlands')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select distinct country from criminals\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Great, Watson! \n",
    "- Now we need to know what everyone of those supspects did wrong, that is the crime type, and desirably, how much they profited from it: Moriarty is not a small fish. He is in the category with th largest total sales.\n",
    "\n",
    "- You'll need to add the crime type and the profit from the files to the table you already put together. Be mindful of the file types. I also believe that the separator in these file maybe different from the files you used previously.\n",
    "-Moriarty made one of the top 5 sales last year. He is not stupid for nicknames, I am pretty sure he doesn't have an alias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution (task 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime_type_profit_France.txt          criminals_Germany.csv\r\n",
      "crime_type_profit_Germany.txt         criminals_Netherlands.csv\r\n",
      "crime_type_profit_Netherlands.txt     criminals_United Kingdom.csv\r\n",
      "crime_type_profit_United Kingdom.txt  id_dates.csv\r\n",
      "criminals_France.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+-----------+\n",
      "|database|tableName               |isTemporary|\n",
      "+--------+------------------------+-----------+\n",
      "|default |criminals_france        |false      |\n",
      "|default |criminals_germany       |false      |\n",
      "|default |criminals_netherlands   |false      |\n",
      "|default |criminals_united_kingdom|false      |\n",
      "|        |criminals               |true       |\n",
      "|        |criminals_with_city     |true       |\n",
      "+--------+------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: United Kingdom, rows: 306\n",
      "country_:  united_kingdom\n",
      "location:  /Users/vk/Documents/Python/holmes_moriarty_sql/src/hive_data/crime_type_profit_united_kingdom\n",
      "Country: Germany, rows: 264\n",
      "country_:  germany\n",
      "location:  /Users/vk/Documents/Python/holmes_moriarty_sql/src/hive_data/crime_type_profit_germany\n",
      "Country: Netherlands, rows: 250\n",
      "country_:  netherlands\n",
      "location:  /Users/vk/Documents/Python/holmes_moriarty_sql/src/hive_data/crime_type_profit_netherlands\n",
      "Country: France, rows: 349\n",
      "country_:  france\n",
      "location:  /Users/vk/Documents/Python/holmes_moriarty_sql/src/hive_data/crime_type_profit_france\n",
      "+--------+--------------------------------+-----------+\n",
      "|database|tableName                       |isTemporary|\n",
      "+--------+--------------------------------+-----------+\n",
      "|default |crime_type_profit_france        |false      |\n",
      "|default |crime_type_profit_germany       |false      |\n",
      "|default |crime_type_profit_netherlands   |false      |\n",
      "|default |crime_type_profit_united_kingdom|false      |\n",
      "|default |criminals_france                |false      |\n",
      "|default |criminals_germany               |false      |\n",
      "|default |criminals_netherlands           |false      |\n",
      "|default |criminals_united_kingdom        |false      |\n",
      "|        |criminals                       |true       |\n",
      "|        |criminals_with_city             |true       |\n",
      "+--------+--------------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_table_template=\"\"\"CREATE EXTERNAL TABLE IF NOT EXISTS crime_type_profit_{} (\n",
    " name string,\n",
    " crime_type string,\n",
    " profit string,\n",
    " country string\n",
    "    )\n",
    "STORED AS ORC\n",
    "LOCATION '{}'\n",
    "\"\"\"\n",
    "\n",
    "# get the data\n",
    "\n",
    "#explore the dataframes: column names, shapes and combine into a single dataframe\n",
    "country_list = [\"United Kingdom\", \"Germany\", \"Netherlands\", \"France\"]\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"crime_type\", StringType(), True),\n",
    "    StructField(\"profit\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True)\n",
    "])\n",
    "\n",
    "for country_ in country_list:\n",
    "    file_name = \"./data/crime_type_profit_{}.txt\".format(country_)\n",
    "    df = spark.read.csv(file_name, header=True, inferSchema=True, sep=\" \")\n",
    "    print(\"Country: {}, rows: {}\".format(country_, df.count()))\n",
    "\n",
    "    df = df.withColumn('country', F.lit(country_))\n",
    "    country_ = \"_\".join(country_.split()).lower()  # 'United Kingdom' has space in it and thus is an illigal table name\n",
    "    print(\"country_: \", country_)\n",
    "    location = os.path.join(hive_folder, 'crime_type_profit_{}'.format(country_))\n",
    "    print(\"location: \", location)\n",
    "    df = apply_schema(df, schema)\n",
    "    df.persist()\n",
    "    df.write.orc(location, mode=\"overwrite\")\n",
    "    df.unpersist()\n",
    "    \n",
    "    # register table\n",
    "    spark.sql(create_table_template.format(country_, location))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "spark.sql(\"show tables\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime_profit count: 1169\n",
      "+---------------+-------------+------+-----------+\n",
      "|           name|   crime_type|profit|    country|\n",
      "+---------------+-------------+------+-----------+\n",
      "|    Isaac David|        theft|   204|     France|\n",
      "|Nikolaj Kallert|pickpocketing|    47|    Germany|\n",
      "|   Leah Winters|    drug sale|  3510|Netherlands|\n",
      "+---------------+-------------+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crime_profit = spark.sql(\"\"\"select * from crime_type_profit_france\n",
    "          union\n",
    "          select * from crime_type_profit_germany\n",
    "          union\n",
    "          select * from crime_type_profit_netherlands\n",
    "          union\n",
    "          select * from crime_type_profit_united_kingdom\"\"\")\n",
    "\n",
    "print(\"crime_profit count: {}\".format(crime_profit.count()))\n",
    "\n",
    "crime_profit.registerTempTable(\"crime_profit\")\n",
    "\n",
    "crime_profit.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|country       |count(1)|\n",
      "+--------------+--------+\n",
      "|Germany       |264     |\n",
      "|France        |349     |\n",
      "|United Kingdom|306     |\n",
      "|Netherlands   |250     |\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crime_profit.groupBy(\"country\").agg(F.count(\"*\")).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+-----+-------------+------+-----------+---------+\n",
      "|id |name                     |alias|crime_type   |profit|country    |city     |\n",
      "+---+-------------------------+-----+-------------+------+-----------+---------+\n",
      "|0  |Henriette Thomas du Peron|     |robbery      |558   |France     |Paris    |\n",
      "|190|Inès Martins de la Morel |     |pickpocketing|44    |France     |Paris    |\n",
      "|215|Isaac Labbe              |     |drug sale    |37260 |France     |Paris    |\n",
      "|244|Aimée-Margot Martins     |     |pickpocketing|26    |France     |Paris    |\n",
      "|297|Olivier Lopez            |Flako|theft        |318   |France     |Paris    |\n",
      "|326|Philippine Traore        |     |theft        |320   |France     |Paris    |\n",
      "|23 |Dipl.-Ing. Dennis Hesse  |     |theft        |44    |Germany    |Frankfurt|\n",
      "|202|Ali Dowerg               |     |theft        |211   |Germany    |Frankfurt|\n",
      "|243|Tomas Mies               |     |pickpocketing|27    |Germany    |Frankfurt|\n",
      "|232|Liam Janssen-Frankhuizen |     |theft        |48    |Netherlands|Amsterdam|\n",
      "+---+-------------------------+-----+-------------+------+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select  a.id, a.name, a.alias, b.crime_type, b.profit, b.country, a.city\n",
    "            from criminals_with_city a\n",
    "            left join crime_profit b\n",
    "                on a.name = b.name and a.country = b.country\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|row_count|\n",
      "+---------+\n",
      "|1169     |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select count(*) as row_count from (\n",
    "                select  a.id, a.name, a.alias, b.crime_type, b.profit, b.country\n",
    "                from criminals a\n",
    "                left join crime_profit b\n",
    "                    on a.name = b.name and a.country = b.country)\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+----------+------------+------+--------------+\n",
      "|id |name                    |alias     |crime_type  |profit|country       |\n",
      "+---+------------------------+----------+------------+------+--------------+\n",
      "|302|Odette Renard du Michaud|null      |weapons sale|498000|France        |\n",
      "|58 |Anthony Mitchell        |null      |weapons sale|495000|United Kingdom|\n",
      "|307|Gabriel Le Schneider    |null      |weapons sale|493000|France        |\n",
      "|62 |Malcolm Cox-Mason       |Handlebars|weapons sale|491000|United Kingdom|\n",
      "|25 |Lily Walter             |Montana   |weapons sale|484000|Netherlands   |\n",
      "|174|Univ.Prof. Augusta Putz |Kiki      |weapons sale|474000|Germany       |\n",
      "|203|Gordon Parker           |null      |weapons sale|467000|United Kingdom|\n",
      "|245|Andrew Smith            |null      |weapons sale|466000|United Kingdom|\n",
      "|171|Constance du Laurent    |null      |weapons sale|453000|France        |\n",
      "|200|Valentine Meunier       |null      |weapons sale|435000|France        |\n",
      "+---+------------------------+----------+------------+------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# order by profit (descending) and \n",
    "# cast profit as int (to keep the same with pyspark notebook; not necessary here)\n",
    "spark.sql(\"\"\"select  a.id, a.name, a.alias, b.crime_type, CAST(b.profit AS INT), b.country\n",
    "            from criminals a\n",
    "            left join crime_profit b\n",
    "                on a.name = b.name and a.country = b.country\n",
    "            order by profit DESC\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "|crime_type   |total_profit|\n",
      "+-------------+------------+\n",
      "|weapons sale |14942000    |\n",
      "|drug sale    |2214270     |\n",
      "|robbery      |96582       |\n",
      "|theft        |95702       |\n",
      "|forgery      |37863       |\n",
      "|pickpocketing|6359        |\n",
      "+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the most profitable crime type\n",
    "\n",
    "spark.sql(\"\"\"select crime_type, CAST(sum(profit) AS INT) as total_profit\n",
    "            from criminals a\n",
    "            left join crime_profit b\n",
    "                on a.name = b.name and a.country = b.country\n",
    "            group by crime_type\n",
    "            order by total_profit DESC\"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------+-----------+\n",
      "|database|tableName                       |isTemporary|\n",
      "+--------+--------------------------------+-----------+\n",
      "|default |crime_type_profit_france        |false      |\n",
      "|default |crime_type_profit_germany       |false      |\n",
      "|default |crime_type_profit_netherlands   |false      |\n",
      "|default |crime_type_profit_united_kingdom|false      |\n",
      "|default |criminals_france                |false      |\n",
      "|default |criminals_germany               |false      |\n",
      "|default |criminals_netherlands           |false      |\n",
      "|default |criminals_united_kingdom        |false      |\n",
      "|        |crime_profit                    |true       |\n",
      "|        |criminals                       |true       |\n",
      "+--------+--------------------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"show tables\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|country       |total_profit|\n",
      "+--------------+------------+\n",
      "|France        |6312000     |\n",
      "|United Kingdom|3914000     |\n",
      "|Germany       |2365000     |\n",
      "|Netherlands   |2351000     |\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the country where with the highest weapons sales\n",
    "\n",
    "spark.sql(\"\"\"select a.country, CAST(sum(profit) AS INT) as total_profit\n",
    "            from criminals a\n",
    "            left join crime_profit b\n",
    "                on a.name = b.name and a.country = b.country\n",
    "            where crime_type = 'weapons sale'\n",
    "            group by a.country\n",
    "            order by total_profit DESC\n",
    "            \"\"\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add crime and profit and register new table\n",
    "\n",
    "criminals_with_profit = spark.sql(\"\"\"select  a.id, a.name, a.alias, b.crime_type, b.profit, b.country\n",
    "            from criminals_with_city a\n",
    "            left join crime_profit b\n",
    "                on a.name = b.name and a.country = b.country\"\"\")\n",
    "\n",
    "criminals_with_profit.cache()\n",
    "criminals_with_profit.registerTempTable(\"criminals_with_profit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------+-----------+\n",
      "|database|tableName                       |isTemporary|\n",
      "+--------+--------------------------------+-----------+\n",
      "|default |crime_type_profit_france        |false      |\n",
      "|default |crime_type_profit_germany       |false      |\n",
      "|default |crime_type_profit_netherlands   |false      |\n",
      "|default |crime_type_profit_united_kingdom|false      |\n",
      "|default |criminals_france                |false      |\n",
      "|default |criminals_germany               |false      |\n",
      "|default |criminals_netherlands           |false      |\n",
      "|default |criminals_united_kingdom        |false      |\n",
      "|        |crime_profit                    |true       |\n",
      "|        |criminals                       |true       |\n",
      "|        |criminals_with_city             |true       |\n",
      "|        |criminals_with_profit           |true       |\n",
      "+--------+--------------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+-----+-------------+------+-------+\n",
      "|id |name                     |alias|crime_type   |profit|country|\n",
      "+---+-------------------------+-----+-------------+------+-------+\n",
      "|0  |Henriette Thomas du Peron|     |robbery      |558   |France |\n",
      "|190|Inès Martins de la Morel |     |pickpocketing|44    |France |\n",
      "|215|Isaac Labbe              |     |drug sale    |37260 |France |\n",
      "|244|Aimée-Margot Martins     |     |pickpocketing|26    |France |\n",
      "|297|Olivier Lopez            |Flako|theft        |318   |France |\n",
      "+---+-------------------------+-----+-------------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from criminals_with_profit\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+------+\n",
      "|id |name                    |profit|\n",
      "+---+------------------------+------+\n",
      "|302|Odette Renard du Michaud|498000|\n",
      "|307|Gabriel Le Schneider    |493000|\n",
      "|171|Constance du Laurent    |453000|\n",
      "|200|Valentine Meunier       |435000|\n",
      "|19 |René Tessier du Lagarde |423000|\n",
      "+---+------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select top 5 to view top criminals in the selected country with selected sales\n",
    "\n",
    "spark.sql(\"\"\"select id, name, CAST(profit as INT) \n",
    "            from criminals_with_profit \n",
    "            where crime_type LIKE 'weapon%' \n",
    "                and country = 'France'\n",
    "            order by profit DESC\n",
    "            \"\"\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3\n",
    "\n",
    "-Watson, I think we got the last piece of the puzzle!\n",
    "\n",
    "I learned that Moriarty doesn't do his dealings on Sunday.\n",
    "\n",
    "That means that the top seller (in the country with the top sale in the last year) who didn't sell on a Sunday and who doesn't have an aliase will be him.\n",
    "\n",
    "All we have to do now is add the date information I just got and determine the weekday for that date. We already know the rest.\n",
    "\n",
    "And we'll send Lestrade right after him!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_dates shape: 1169\n",
      "+---+----------+-------+\n",
      "| id|      date|country|\n",
      "+---+----------+-------+\n",
      "|  0|2020-06-15| France|\n",
      "|  1|2020-01-06| France|\n",
      "|  2|2020-08-03| France|\n",
      "|  3|2020-06-19| France|\n",
      "+---+----------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_dates = spark.read.csv(\"./data/id_dates.csv\", header=True, inferSchema=True)\n",
    "print(\"id_dates shape: {}\".format(id_dates.count()))\n",
    "id_dates.show(4)\n",
    "id_dates.registerTempTable(\"id_dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------+\n",
      "|id |date      |country       |\n",
      "+---+----------+--------------+\n",
      "|302|2020-08-01|United Kingdom|\n",
      "|302|2020-01-29|France        |\n",
      "+---+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from id_dates where id = 302\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+-----+-------------+------+--------------+\n",
      "|id |name                    |alias|crime_type   |profit|country       |\n",
      "+---+------------------------+-----+-------------+------+--------------+\n",
      "|302|Anthony Weston          |     |pickpocketing|43    |United Kingdom|\n",
      "|302|Odette Renard du Michaud|     |weapons sale |498000|France        |\n",
      "+---+------------------------+-----+-------------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from criminals_with_profit where id = 302\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id_dates.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+-------+\n",
      "|id |date      |country|day_num|\n",
      "+---+----------+-------+-------+\n",
      "|0  |2020-06-15|France |0      |\n",
      "|1  |2020-01-06|France |0      |\n",
      "|2  |2020-08-03|France |0      |\n",
      "|3  |2020-06-19|France |4      |\n",
      "|4  |2020-11-20|France |4      |\n",
      "+---+----------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select *, weekday(date) as day_num from id_dates\").registerTempTable(\"dates_with_day_number\")\n",
    "spark.sql(\"select * from dates_with_day_number\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|num|\n",
      "+---+\n",
      "|0  |\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a known date to determine how day numbering is setup by default\n",
    "# 2020-12-14 is Monday\n",
    "spark.sql(\"select weekday('2020-12-14') as num\").show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+-------+--------+\n",
      "|id |date      |country|day_num|weekday |\n",
      "+---+----------+-------+-------+--------+\n",
      "|0  |2020-06-15|France |0      |Monday  |\n",
      "|1  |2020-01-06|France |0      |Monday  |\n",
      "|2  |2020-08-03|France |0      |Monday  |\n",
      "|3  |2020-06-19|France |4      |Friday  |\n",
      "|4  |2020-11-20|France |4      |Friday  |\n",
      "|5  |2020-01-11|France |5      |Saturday|\n",
      "|6  |2020-04-23|France |3      |Thursday|\n",
      "|7  |2020-09-27|France |6      |Sunday  |\n",
      "|8  |2020-05-08|France |4      |Friday  |\n",
      "|9  |2020-04-09|France |3      |Thursday|\n",
      "+---+----------+-------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select *, \n",
    "            case day_num\n",
    "             when 0  then 'Monday'\n",
    "             when 1 then'Tuesday'\n",
    "             when 2 then 'Wednesday'\n",
    "             when 3 then 'Thursday'\n",
    "             when 4 then'Friday'\n",
    "             when 5 then 'Saturday'\n",
    "             when 6 then 'Sunday'\n",
    "        end as weekday\n",
    "        from dates_with_day_number\"\"\").show(10, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-------+\n",
      "|id |date      |weekday |country|\n",
      "+---+----------+--------+-------+\n",
      "|0  |2020-06-15|Monday  |France |\n",
      "|1  |2020-01-06|Monday  |France |\n",
      "|2  |2020-08-03|Monday  |France |\n",
      "|3  |2020-06-19|Friday  |France |\n",
      "|4  |2020-11-20|Friday  |France |\n",
      "|5  |2020-01-11|Saturday|France |\n",
      "|6  |2020-04-23|Thursday|France |\n",
      "|7  |2020-09-27|Sunday  |France |\n",
      "|8  |2020-05-08|Friday  |France |\n",
      "|9  |2020-04-09|Thursday|France |\n",
      "+---+----------+--------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select only needed columns and register a table\n",
    "df = spark.sql(\"\"\"select id, date,\n",
    "            case day_num\n",
    "             when 0  then 'Monday'\n",
    "             when 1 then'Tuesday'\n",
    "             when 2 then 'Wednesday'\n",
    "             when 3 then 'Thursday'\n",
    "             when 4 then'Friday'\n",
    "             when 5 then 'Saturday'\n",
    "             when 6 then 'Sunday'\n",
    "        end as weekday,\n",
    "        country\n",
    "        from dates_with_day_number\"\"\")\n",
    "\n",
    "df.registerTempTable(\"id_dates_with_weekday\")\n",
    "\n",
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+-----+-------------+------+-------+--------+\n",
      "|id |name                     |alias|crime_type   |profit|country|weekday |\n",
      "+---+-------------------------+-----+-------------+------+-------+--------+\n",
      "|0  |Henriette Thomas du Peron|     |robbery      |558   |France |Monday  |\n",
      "|190|Inès Martins de la Morel |     |pickpocketing|44    |France |Friday  |\n",
      "|215|Isaac Labbe              |     |drug sale    |37260 |France |Thursday|\n",
      "|244|Aimée-Margot Martins     |     |pickpocketing|26    |France |Friday  |\n",
      "|297|Olivier Lopez            |Flako|theft        |318   |France |Sunday  |\n",
      "+---+-------------------------+-----+-------------+------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"select a.*, b.weekday from \n",
    "                criminals_with_profit a\n",
    "                inner join id_dates_with_weekday b \n",
    "                on a.id = b.id \n",
    "                and a.country = b.country\"\"\")\n",
    "\n",
    "df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable(\"criminals_with_weekday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------+\n",
      "|name                    |profit|\n",
      "+------------------------+------+\n",
      "|Odette Renard du Michaud|498000|\n",
      "|Constance du Laurent    |453000|\n",
      "|René Tessier du Lagarde |423000|\n",
      "|Zoé Guibert de la Levy  |364000|\n",
      "|Denis Lesage            |328000|\n",
      "|Henriette Charpentier   |282000|\n",
      "|Thomas Couturier        |267000|\n",
      "|daisy Toussaint         |266000|\n",
      "|Suzanne Levy            |216000|\n",
      "|Zacharie Samson         |208000|\n",
      "+------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show top 5 salesmen in the selected country\n",
    "df_final = spark.sql(\"\"\"select name, CAST(profit AS INT)\n",
    "                            from criminals_with_weekday\n",
    "                            where\n",
    "                                country = 'France' \n",
    "                                and alias = '' \n",
    "                                and crime_type = 'weapons sale'\n",
    "                                and weekday != 'Sunday'\n",
    "                                order by profit DESC\"\"\")\n",
    "\n",
    "df_final.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moriarty_name =  df_final.select(\"name\").collect()[0][0]\n",
    "print(\"The name Moriarty is hiding behind: {}\".format(moriarty_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
