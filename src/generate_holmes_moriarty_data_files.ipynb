{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data generation for the puzzle\n",
      "n_agents:  349\n",
      "n_agents:  306\n",
      "n_agents:  264\n",
      "n_agents:  250\n",
      "Initial shape: 1169\n",
      "Initial shape deduped by name: 1169\n",
      "crime_type_big_sales: weapons sale\n",
      "country_with_top_sales: France\n",
      "df_moriarty shape: 23.\n",
      "Name to replace: Odette Renard du Michaud\n",
      "Final shape: 1169\n",
      "crime_type_big_sales: weapons sale\n",
      "country_with_top_sales: France\n",
      "Identified moriarty_name: Odette Renard du Michaud\n",
      "Saved: ./data/criminals_France.csv\n",
      "Saved: ./data/crime_type_profit_France.txt\n",
      "Saved: ./data/criminals_United Kingdom.csv\n",
      "Saved: ./data/crime_type_profit_United Kingdom.txt\n",
      "Saved: ./data/criminals_Germany.csv\n",
      "Saved: ./data/crime_type_profit_Germany.txt\n",
      "Saved: ./data/criminals_Netherlands.csv\n",
      "Saved: ./data/crime_type_profit_Netherlands.txt\n",
      "Saved: ./data/id_dates.csv\n",
      "main_criminals_df count: 1169\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "12/04/2020\n",
    "Purpose: to generate a table with fake data for Holmes-Moriarty pandas/pyspark/sql puzzle.\n",
    "\"\"\"\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from faker import Faker\n",
    "from faker.generator import random\n",
    "\n",
    "from helpers import main_dict, weekday, remove_data_files\n",
    "from helpers import identify_crime_type_country, identify_moriarty\n",
    "\n",
    "from helpers import seed  # change the seed in helpers to change the generated data\n",
    "\n",
    "Faker.seed(seed)\n",
    "faker = Faker()\n",
    "\n",
    "\n",
    "def parse_main_dict():\n",
    "    \"\"\"Parses dict to get the lists of\n",
    "    countries, cities, and fakers. Fakers allow generation of region specific fake data.\n",
    "    Also generates total number of agents\n",
    "    \"\"\"\n",
    "    Faker.seed(seed)  # required to generate reproducible data\n",
    "\n",
    "    countries = main_dict.keys()\n",
    "    cities = [v['city'] for v in main_dict.values()]\n",
    "    fakers = [Faker(v['faker_abbrev']) for v in main_dict.values()]\n",
    "    total_agents = sum([v['number_of_agents'] for v in main_dict.values()])\n",
    "\n",
    "    return fakers, countries, cities, total_agents\n",
    "\n",
    "\n",
    "def generate_lat_lon(country, main_dict):\n",
    "    \"\"\"\n",
    "    Generates latitude and longitude for a city in the country.\n",
    "    The values have a defined range of randomness near\n",
    "    the city (the coordinates of the city are from the main_dict).\n",
    "    \"\"\"\n",
    "    lats = []\n",
    "    lons = []\n",
    "    n_agents = main_dict[country]['number_of_agents']\n",
    "    print(\"n_agents: \", n_agents)\n",
    "    for i in range(n_agents):\n",
    "        lat = float(main_dict[country]['city_coordinates'][0])\n",
    "        lon = float(main_dict[country]['city_coordinates'][1])\n",
    "        dev = 0.25\n",
    "        min_lat, max_lat = lat - dev, lat + dev\n",
    "        min_lon, max_lon = lon - dev, lon + dev\n",
    "        round_to = 4\n",
    "        lat1 = round(random.uniform(min_lat, max_lat), round_to)\n",
    "        lon1 = round(random.uniform(min_lon, max_lon), round_to)\n",
    "        lats.append(str(lat1))\n",
    "        lons.append(str(lon1))\n",
    "\n",
    "    return lats, lons\n",
    "\n",
    "\n",
    "def generate_aliases(df, n_agents):\n",
    "    \"\"\"\"\"\"\n",
    "    with open('./extra_data/aliases.txt', 'r') as f:\n",
    "        aliases = [i.capitalize() for i in f.read().split()]\n",
    "\n",
    "    aliases_unique = list(set(aliases))\n",
    "    aliases = aliases_unique + [\"\" for i in range(n_agents - len(aliases_unique))]\n",
    "    random.shuffle(aliases)\n",
    "\n",
    "    df['alias'] = pd.Series(aliases)  # create a column from the list\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_country_criminals_df(regional_faker, country):\n",
    "    \"\"\"\n",
    "    Creates a dataframe of criminals with columns: name, nickname, address, city,\n",
    "    country, latitude, longitude using regional fakers using predefined and random\n",
    "    values (number of agents) defined in the main dict.\n",
    "    \"\"\"\n",
    "\n",
    "    n_agents = main_dict[country]['number_of_agents']\n",
    "\n",
    "    name_col = [regional_faker.name() for i in range(n_agents)]\n",
    "    address_col = [regional_faker.address().replace('\\n', ' ') for i in\n",
    "                   range(n_agents)]\n",
    "\n",
    "    lats_col, lons_col = generate_lat_lon(country, main_dict)\n",
    "    cols_data = [name_col, address_col, lats_col, lons_col]\n",
    "\n",
    "    column_names = ['name', 'address', 'lat', 'lon']\n",
    "\n",
    "    country_criminals_dict = {col: data for (col, data) in zip(column_names, cols_data)}\n",
    "    df = pd.DataFrame(country_criminals_dict)\n",
    "\n",
    "    # add columns of country and city\n",
    "    df['country'] = country\n",
    "    df['city'] = main_dict[country]['city']\n",
    "    df['id'] = df.index\n",
    "\n",
    "    df = df[['name', 'id', 'address', 'lat', 'lon', 'country', 'city']]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_date_weekday_column(df):\n",
    "    \"\"\"Creates random dates within the last year and adds it as 'datetime64' column \"\"\"\n",
    "\n",
    "    faker_en = Faker('en_GB')\n",
    "\n",
    "    def date_using_faker(x):\n",
    "        return faker_en.date_between(start_date='-360d', end_date='today')\n",
    "\n",
    "    df['date'] = df['name'].apply(date_using_faker)  # can use any column; here we are using 'name'\n",
    "    df['date'] = df['date'].astype('datetime64')\n",
    "\n",
    "    df[\"weekday\"] = df[\"date\"].apply(weekday)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_date_not_sunday(value):\n",
    "    \"\"\"Creates fake date that is not a Sunday\"\"\"\n",
    "\n",
    "    faker_en = Faker('en_GB')\n",
    "    fake_date = faker_en.date_between(start_date='-360d', end_date='today')\n",
    "\n",
    "    while weekday(fake_date) == 'Sunday':\n",
    "        fake_date = faker_en.date_between(start_date='-360d', end_date='today')\n",
    "    return fake_date\n",
    "\n",
    "\n",
    "def add_moriarty_profile(df, crime_type_, country_):\n",
    "    \"\"\"Makes sure the solution's date is not 'Sunday' and alias is None.\"\"\"\n",
    "\n",
    "    faker_en = Faker('en_GB')\n",
    "\n",
    "    df_moriarty = df.loc[(df.country == country_) & (df.crime_type == crime_type_)] \\\n",
    "        .sort_values('profit', ascending=False).reset_index()\n",
    "    print(\"df_moriarty shape: {}.\".format(df_moriarty.shape[0]))\n",
    "    hidden_moriarty_name = df_moriarty.name[0]\n",
    "    print(\"Name to replace: {}\".format(hidden_moriarty_name))\n",
    "    df_moriarty = df.loc[df.name == hidden_moriarty_name]\n",
    "    df_moriarty = df_moriarty.copy()\n",
    "\n",
    "    df_not_moriarty = df.loc[df.name != hidden_moriarty_name]\n",
    "\n",
    "    df_moriarty[\"date\"] = add_date_not_sunday('test')\n",
    "    df_moriarty[\"date\"] = df_moriarty[\"date\"].astype('datetime64')\n",
    "    df_moriarty['alias'] = \"\"\n",
    "\n",
    "    df = pd.concat([df_not_moriarty, df_moriarty])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_crime_types(df):\n",
    "    \"\"\"\n",
    "    Generates a column of crime types  for all criminals.\n",
    "    Each type has its own defined fraction of all criminals to ensure\n",
    "    weapons sales has the most sales (in money units) and\n",
    "    that other crime types profits look realistic.\n",
    "    \"\"\"\n",
    "\n",
    "    crimes_dict = {'weapons sale': {'factor': 100.0, 'fraction': 0.05},\n",
    "                   'drug sale': {'factor': 9.0, 'fraction': 0.08},\n",
    "                   'robbery': {'factor': 0.2, 'fraction': 0.17},\n",
    "                   'forgery': {'factor': 0.12, 'fraction': 0.10},\n",
    "                   'theft': {'factor': 0.08, 'fraction': 0.4},\n",
    "                   'pickpocketing': {'factor': 0.01, 'fraction': 0.2}\n",
    "                   }\n",
    "\n",
    "    full_crimes_list = []\n",
    "    for k in list(crimes_dict.keys()):\n",
    "        if k != list(crimes_dict.keys())[-1]:\n",
    "            times = int(df.shape[0] * crimes_dict[k]['fraction'])\n",
    "        else:\n",
    "            times = df.shape[0] - len(full_crimes_list)\n",
    "        crimes = [k for i in range(times)]\n",
    "        full_crimes_list += crimes\n",
    "\n",
    "    random.shuffle(full_crimes_list)\n",
    "\n",
    "    df['crime_type'] = full_crimes_list\n",
    "\n",
    "    def generate_criminal_profits(crime_type):\n",
    "        \"\"\"\n",
    "        Adds profit information for each criminal.\n",
    "        Factor from the dict is used to make crime types profits look realistic\n",
    "        \"\"\"\n",
    "        return int(-(crimes_dict[crime_type]['factor'] * (-random.randrange(100, 5000, 10)) // 1))\n",
    "\n",
    "    df['profit'] = df['crime_type'].apply(generate_criminal_profits)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_main_df_into_countries(df):\n",
    "    \"\"\"\n",
    "    Splits the main df into 5 dfs based on the country for unioning in the test.\n",
    "    Include columns: name, alias, lat, lon.\n",
    "    (with names specific to the corresponding countries).\n",
    "    Save to the current folder.\n",
    "    \"\"\"\n",
    "    df_all_countries = df.copy()\n",
    "\n",
    "    country_list = df_all_countries[\"country\"].unique().tolist()\n",
    "\n",
    "    dfs_dict = {}\n",
    "    for num, country_ in enumerate(country_list):\n",
    "\n",
    "        df_country = df_all_countries.loc[(df_all_countries.country == country_)]\n",
    "        df = df_country.copy()\n",
    "        df = df[[\"id\", \"name\", \"alias\", \"lat\", \"lon\"]]\n",
    "\n",
    "        # add country-specific column names\n",
    "        if country_ == \"Germany\" or country_ == \"Netherlands\":\n",
    "            cols = [\"id\", \"benennen\", \"aliasnamen\", \"breitengrad\", \"länge\"]\n",
    "        elif country_ == \"France\":\n",
    "            cols = [\"id\", \"nom\", \"pseudonyme\", \"latitude\", \"longitude\"]\n",
    "        else:\n",
    "            cols = [\"id\", \"name\", \"alias\", \"latitude\", \"longitude\"]\n",
    "\n",
    "        # assign new column names\n",
    "        df.columns = cols\n",
    "        # save as file with country name\n",
    "        file_name = \"./data/criminals_{}.csv\".format(country_)\n",
    "        print(\"Saved: {}\".format(file_name))\n",
    "        df.to_csv(file_name, header=True, index=False)\n",
    "\n",
    "        # generate crime_type, profit csvs\n",
    "        df = df_country.copy()\n",
    "        df = df[[\"name\", \"crime_type\", \"profit\"]]\n",
    "        file_name = \"./data/crime_type_profit_{}.txt\".format(country_)\n",
    "        print(\"Saved: {}\".format(file_name))\n",
    "        df.to_csv(file_name, sep=' ', header=True, index=False)\n",
    "\n",
    "\n",
    "def save_id_date_df(df):\n",
    "    \"\"\"\n",
    "    Adds date of the last crime. Leave only 'id' and 'date' (for joining on id)\n",
    "    \"\"\"\n",
    "\n",
    "    df_id_date = df[[\"id\", \"date\", \"country\"]]\n",
    "    file_name = \"./data/id_dates.csv\"\n",
    "    df_id_date.to_csv(file_name, header=True, index=False)\n",
    "    print(\"Saved: {}\".format(file_name))\n",
    "\n",
    "\n",
    "def generate_df_with_criminals():\n",
    "    \"\"\"\n",
    "    Creates a pandas dataframe of criminals for all countries.\n",
    "    1.Generates aliases.\n",
    "    2. Iterates over countries to create dataframe of criminals per country.\n",
    "    3. Combines all country dfs into the main dataframe.\n",
    "    \"\"\"\n",
    "    remove_data_files()\n",
    "\n",
    "    fakers, countries, cities, n_agents = parse_main_dict()\n",
    "\n",
    "    # creates the backbone of the future df with criminals using regional fakers\n",
    "    country_criminals_dfs = []\n",
    "    for faker, country in zip(fakers, countries):\n",
    "        df = generate_country_criminals_df(faker, country)\n",
    "        country_criminals_dfs.append(df)\n",
    "    df = pd.concat(country_criminals_dfs, ignore_index=True, sort=False)\n",
    "\n",
    "    df = generate_aliases(df, n_agents)  # from a .txt file\n",
    "\n",
    "    print(\"Initial shape: {}\".format(df.shape[0]))\n",
    "    df.drop_duplicates(subset=['name'], inplace=True)\n",
    "    print(\"Initial shape deduped by name: {}\".format(df.shape[0]))\n",
    "\n",
    "    # add date, weekday columns\n",
    "    df = add_date_weekday_column(df)\n",
    "\n",
    "    # add crime_type and profit columns\n",
    "    df = add_crime_types(df)\n",
    "\n",
    "    # select columns and set their order\n",
    "    df = df[['name', 'alias', 'id', 'address', 'lat', 'lon', 'country',\n",
    "             'city', 'date', 'crime_type', 'profit', 'weekday']]\n",
    "    df[[\"name\"]].drop_duplicates()\n",
    "\n",
    "    # generating solution\n",
    "    crime_type_, country_ = identify_crime_type_country(df)\n",
    "\n",
    "    df = add_moriarty_profile(df, crime_type_, country_)\n",
    "    print(\"Final shape: {}\".format(df.shape[0]))\n",
    "\n",
    "    identify_moriarty(df, seed, save=True)\n",
    "\n",
    "    # generating data\n",
    "    split_main_df_into_countries(df)  # saves csvs\n",
    "\n",
    "    save_id_date_df(df)  # save id and date for future join\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        print(\"Starting data generation for the puzzle\")\n",
    "        main_criminals_df = generate_df_with_criminals()\n",
    "        print(\"main_criminals_df count: {}\".format(main_criminals_df.shape[0]))\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Exception starting generate_df_with_criminals.\")\n",
    "        print(sys.exc_info())\n",
    "        sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
